#!/usr/bin/env python3
"""
LLM Inline - OpenAI-compatible command line LLM interface

Usage: llmi ask "your question here" [--file file_path]
"""

import os
import sys
import json
import subprocess
import requests
from openai import OpenAI
from pathlib import Path


def read_file_content(file_path: str) -> dict:
    """
    è¯»å–æ–‡ä»¶å†…å®¹ï¼Œè¿”å›æ–‡ä»¶ä¿¡æ¯å­—å…¸
    æ”¯æŒç›¸å¯¹è·¯å¾„è½¬æ¢
    """
    try:
        # æ”¯æŒç›¸å¯¹è·¯å¾„
        abs_path = Path(file_path).expanduser().resolve()
        
        if not abs_path.exists():
            return {"error": f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"}
        
        if not abs_path.is_file():
            return {"error": f"è·¯å¾„ä¸æ˜¯æ–‡ä»¶: {file_path}"}
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼Œé¿å…ä¸Šä¼ è¿‡å¤§æ–‡ä»¶
        file_size = abs_path.stat().st_size
        if file_size > 10 * 1024 * 1024:  # 10MB limit
            return {"error": f"æ–‡ä»¶è¿‡å¤§ï¼Œè¶…è¿‡10MBé™åˆ¶: {file_path}"}
        
        # è¯»å–æ–‡ä»¶å†…å®¹
        try:
            with open(abs_path, 'r', encoding='utf-8') as f:
                content = f.read()
            is_binary = False
        except (UnicodeDecodeError, Exception):
            # å¦‚æœæ˜¯äºŒè¿›åˆ¶æ–‡ä»¶ï¼Œè¯»å–ä¸ºbase64
            import base64
            with open(abs_path, 'rb') as f:
                binary_content = f.read()
            content = base64.b64encode(binary_content).decode('utf-8')
            is_binary = True
        
        return {
            "success": True,
            "path": str(abs_path),
            "filename": abs_path.name,
            "content": content,
            "size": file_size,
            "is_binary": is_binary
        }
        
    except Exception as e:
        return {"error": f"è¯»å–æ–‡ä»¶å¤±è´¥: {str(e)}"}


def get_shell_info():
    """è·å–å½“å‰shellç¯å¢ƒå’Œç›®å½•ä¿¡æ¯"""
    shell = os.environ.get('SHELL', '/bin/sh')
    current_dir = os.getcwd()
    return {
        "shell": shell,
        "current_directory": current_dir
    }


def create_structured_prompt(user_input: str, shell_info: dict, file_info: dict = None) -> list:
    """
    åˆ›å»ºç»“æ„åŒ–çš„æç¤ºä¿¡æ¯
    è¦æ±‚LLMä»¥ç‰¹å®šæ ¼å¼è¿”å›å¯ç›´æ¥ä½¿ç”¨çš„å‘½ä»¤
    """
    
    # æ„å»ºç³»ç»Ÿæç¤º
    system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªå‘½ä»¤è¡ŒåŠ©æ‰‹ï¼Œå¸®åŠ©ç”¨æˆ·è§£å†³shellå‘½ä»¤ç›¸å…³é—®é¢˜ã€‚

å½“å‰ç¯å¢ƒ:
- Shell: {shell_info['shell']}
- å½“å‰ç›®å½•: {shell_info['current_directory']}"""

    # å¦‚æœæœ‰æ–‡ä»¶é™„ä»¶ï¼Œæ·»åŠ æ–‡ä»¶ä¿¡æ¯
    if file_info and file_info.get('success'):
        file_info_text = f"""

æ–‡ä»¶é™„ä»¶ä¿¡æ¯:
- æ–‡ä»¶å: {file_info['filename']}
- æ–‡ä»¶è·¯å¾„: {file_info['path']}
- æ–‡ä»¶å¤§å°: {file_info['size']} bytes
- æ˜¯å¦ä¸ºäºŒè¿›åˆ¶æ–‡ä»¶: {'æ˜¯' if file_info['is_binary'] else 'å¦'}
- æ–‡ä»¶å†…å®¹: 
{file_info['content'] if not file_info['is_binary'] else '[äºŒè¿›åˆ¶å†…å®¹ï¼Œå·²ç¼–ç ä¸ºbase64]'}"""
        
        system_prompt += file_info_text
    
    system_prompt += """

å¦‚æœç”¨æˆ·çš„é—®é¢˜æ˜¯å…³äºå¦‚ä½•è¾“å…¥bash/zshå‘½ä»¤çš„ï¼Œä½ å¿…é¡»ä»¥ä»¥ä¸‹æ ¼å¼è¿”å›å¯ä»¥ç›´æ¥ä½¿ç”¨çš„å‘½ä»¤:
```command
å…·ä½“çš„å‘½ä»¤å†…å®¹
```

å¦‚æœé—®é¢˜ä¸æ¶‰åŠå‘½ä»¤ï¼Œåˆ™æ­£å¸¸å›ç­”å³å¯ã€‚

è¦æ±‚:
1. å¯¹äºéœ€è¦å‘½ä»¤çš„é—®ç­”ï¼Œå¿…é¡»ä½¿ç”¨ä¸Šé¢çš„æ ¼å¼å°†å‘½ä»¤åŒ…è£¹åœ¨```commandä»£ç å—ä¸­ã€‚

ç¤ºä¾‹:
ç”¨æˆ·: "æ€ä¹ˆåˆ—å‡ºå½“å‰ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶,å¹¶ä¸”èƒ½çœ‹åˆ°æ¯ä¸ªæ–‡ä»¶çš„æ‰©å±•åå’Œæ–‡ä»¶å¤§å°?"

ä½ çš„å›ç­”åº”è¯¥æ˜¯:
```command
ls -l
```
"""

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_input}
    ]

    return messages


def call_llm(messages: list) -> str:
    """è°ƒç”¨OpenAIå…¼å®¹çš„API"""
    try:
        client = OpenAI(
            api_key=os.environ.get('LLM_API_KEY'),
            base_url=os.environ.get('LLM_BASE_URL')
        )

        # æ„å»ºAPIå‚æ•°
        api_params = {
            "model": os.environ.get('LLM_MODEL_NAME', 'doubao-seed-1.6-flash'),
            "messages": messages,
            "max_tokens": 1000,
            "temperature": 0.3
        }

        # å¦‚æœæœ‰æ–‡ä»¶é™„ä»¶ï¼Œç›´æ¥åœ¨ç³»ç»Ÿæç¤ºä¸­åŒ…å«æ–‡ä»¶å†…å®¹ï¼ˆä¸ä½¿ç”¨image_urlæ ¼å¼ï¼‰
        # æˆ‘ä»¬å·²ç»åœ¨create_structured_promptä¸­å¤„ç†äº†æ–‡ä»¶å†…å®¹
        # è¿™é‡Œä¸å†éœ€è¦ç‰¹æ®Šå¤„ç†

        response = client.chat.completions.create(**api_params)

        return response.choices[0].message.content

    except Exception as e:
        return f"Error calling LLM: {str(e)}"


def extract_command(llm_response: str) -> str:
    """
    ä»LLMå“åº”ä¸­æå–å‘½ä»¤
    å¦‚æœæ‰¾åˆ°```commandä»£ç å—ï¼Œè¿”å›å…¶ä¸­çš„å‘½ä»¤å†…å®¹
    """
    import re

    # åŒ¹é…```commandä»£ç å—
    pattern = r'```command\s*\n(.*?)\n```'
    match = re.search(pattern, llm_response, re.DOTALL)
    if match:
        return match.group(1).strip()
    return None


def get_skills_dir() -> Path:
    """è·å–ç”¨æˆ·æŠ€èƒ½ç›®å½•"""
    return Path.home() / ".llm-inline" / "skills"


def load_skill(skill_name: str) -> dict:
    """åŠ è½½æŠ€èƒ½é…ç½®"""
    skills_dir = get_skills_dir()
    skill_dir = skills_dir / skill_name
    config_file = skill_dir / "skill.json"
    
    if not config_file.exists():
        return None
    
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception:
        return None


def list_skills() -> list:
    """åˆ—å‡ºæ‰€æœ‰å·²å®‰è£…çš„æŠ€èƒ½"""
    skills_dir = get_skills_dir()
    if not skills_dir.exists():
        return []
    
    skills = []
    for skill_dir in skills_dir.iterdir():
        if skill_dir.is_dir():
            config = load_skill(skill_dir.name)
            if config:
                skills.append(config)
    return skills


def install_skill_from_url(url: str) -> bool:
    """ä»URLå®‰è£…æŠ€èƒ½"""
    try:
        print(f"ğŸ“¥ æ­£åœ¨ä¸‹è½½æŠ€èƒ½é…ç½®: {url}")
        
        # å¤„ç†file://åè®®
        if url.startswith('file://'):
            file_path = url[7:]  # ç§»é™¤file://
            if not os.path.exists(file_path):
                print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                return False
            
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
        else:
            response = requests.get(url, timeout=30)
            response.raise_for_status()
            content = response.text
        
        # å°è¯•è§£æJSON
        try:
            config = json.loads(content)
        except json.JSONDecodeError:
            print("âŒ ä¸‹è½½çš„æ–‡ä»¶ä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼")
            return False
        
        # éªŒè¯å¿…è¦å­—æ®µ
        required_fields = ['name', 'description', 'version']
        for field in required_fields:
            if field not in config:
                print(f"âŒ æŠ€èƒ½é…ç½®ç¼ºå°‘å¿…è¦å­—æ®µ: {field}")
                return False
        
        skill_name = config['name']
        skills_dir = get_skills_dir()
        skill_dir = skills_dir / skill_name
        skill_dir.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜é…ç½®æ–‡ä»¶
        config_file = skill_dir / "skill.json"
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        
        # ä¸‹è½½å¤„ç†è„šæœ¬ï¼ˆå¦‚æœæœ‰ï¼‰
        if 'handler' in config:
            # æ„å»ºhandler URL
            if url.startswith('file://'):
                # å¯¹äºfile://ï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶çš„ç›®å½•
                base_path = os.path.dirname(url[7:])
                handler_path = os.path.join(base_path, config['handler'])
                handler_url = f"file://{handler_path}"
            else:
                # å¯¹äºHTTP(S) URLsï¼Œæ­£å¸¸æ‹¼æ¥
                handler_url = url.rsplit('/', 1)[0] + '/' + config['handler']
                
            try:
                print(f"ğŸ“¥ æ­£åœ¨ä¸‹è½½å¤„ç†è„šæœ¬: {handler_url}")
                
                # å¤„ç†file://åè®®
                if handler_url.startswith('file://'):
                    handler_file_path = handler_url[7:]  # ç§»é™¤file://
                    if not os.path.exists(handler_file_path):
                        print(f"âŒ å¤„ç†è„šæœ¬æ–‡ä»¶ä¸å­˜åœ¨: {handler_file_path}")
                        return False
                    
                    with open(handler_file_path, 'r', encoding='utf-8') as f:
                        handler_content = f.read()
                else:
                    handler_response = requests.get(handler_url, timeout=30)
                    handler_response.raise_for_status()
                    handler_content = handler_response.text
                
                handler_file = skill_dir / config['handler']
                with open(handler_file, 'w', encoding='utf-8') as f:
                    f.write(handler_content)
                
                # ä½¿è„šæœ¬å¯æ‰§è¡Œ
                os.chmod(handler_file, 0o755)
                
            except Exception as e:
                print(f"âš ï¸ ä¸‹è½½å¤„ç†è„šæœ¬å¤±è´¥: {e}")
        
        print(f"âœ… æŠ€èƒ½ '{skill_name}' å®‰è£…æˆåŠŸ!")
        return True
        
    except Exception as e:
        print(f"âŒ å®‰è£…æŠ€èƒ½å¤±è´¥: {e}")
        return False


def execute_skill(skill_name: str, args: list) -> bool:
    """æ‰§è¡ŒæŠ€èƒ½"""
    config = load_skill(skill_name)
    if not config:
        print(f"âŒ æŠ€èƒ½ '{skill_name}' ä¸å­˜åœ¨")
        return False
    
    try:
        skill_dir = get_skills_dir() / skill_name
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å¤„ç†è„šæœ¬
        if 'handler' in config:
            handler_file = skill_dir / config['handler']
            if handler_file.exists():
                # åŠ¨æ€å¯¼å…¥å¹¶æ‰§è¡ŒPythonè„šæœ¬
                sys.path.insert(0, str(skill_dir))
                try:
                    module_name = config['handler'].replace('.py', '')
                    module = __import__(module_name)
                    
                    # æ³¨å…¥LLMè¿è¡Œæ—¶ç¯å¢ƒ
                    import llmi_runtime
                    
                    # è°ƒç”¨mainå‡½æ•°
                    if hasattr(module, 'main'):
                        result = module.main(args)
                        return result if isinstance(result, bool) else True
                    else:
                        print(f"âŒ æŠ€èƒ½è„šæœ¬ç¼ºå°‘mainå‡½æ•°")
                        return False
                        
                except ImportError as e:
                    print(f"âŒ å¯¼å…¥æŠ€èƒ½è„šæœ¬å¤±è´¥: {e}")
                    return False
                except Exception as e:
                    print(f"âŒ æ‰§è¡ŒæŠ€èƒ½è„šæœ¬å¤±è´¥: {e}")
                    return False
                finally:
                    # æ¸…ç†sys.path
                    if str(skill_dir) in sys.path:
                        sys.path.remove(str(skill_dir))
            else:
                print(f"âŒ æŠ€èƒ½å¤„ç†è„šæœ¬ä¸å­˜åœ¨: {config['handler']}")
                return False
        else:
            # æ²¡æœ‰å¤„ç†è„šæœ¬ï¼Œæ˜¾ç¤ºæŠ€èƒ½ä¿¡æ¯
            print(f"ğŸ“‹ æŠ€èƒ½: {config['name']}")
            print(f"ğŸ“ æè¿°: {config['description']}")
            print(f"ğŸ“¦ ç‰ˆæœ¬: {config['version']}")
            if 'parameters' in config:
                print("ğŸ“¥ å‚æ•°:")
                for param in config['parameters']:
                    required = "å¿…éœ€" if param.get('required', False) else "å¯é€‰"
                    default = f" (é»˜è®¤: {param['default']})" if 'default' in param else ""
                    print(f"  - {param['name']}: {param['description']} [{required}]{default}")
            return True
            
    except Exception as e:
        print(f"âŒ æ‰§è¡ŒæŠ€èƒ½å¤±è´¥: {e}")
        return False


def ensure_llm_env() -> None:
    """æ£€æŸ¥å¿…è¦çš„ç¯å¢ƒå˜é‡æ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™æç¤ºåé€€å‡º"""
    required_vars = ['LLM_API_KEY', 'LLM_BASE_URL', 'LLM_MODEL_NAME']
    missing = [v for v in required_vars if not os.environ.get(v)]
    if missing:
        print(f"âŒ ç¼ºå°‘å¿…è¦ç¯å¢ƒå˜é‡: {', '.join(missing)}")
        print("è¯·å…ˆè¿è¡Œ: source llm-switch å¹¶ç¡®ä¿å·²è®¾ç½® LLM_API_KEY, LLM_BASE_URL, LLM_MODEL_NAME")
        sys.exit(2)


def main():
    import sys
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å‚æ•°
    if len(sys.argv) < 2:
        print("âŒ è¯·æä¾›é—®é¢˜æˆ–æŒ‡ä»¤")
        print("Usage:")
        print("  llmi \"your question here\" [--file file_path]  # è¯¢é—®é—®é¢˜")
        print("  llmi ask \"your question here\" [--file file_path]  # è¯¢é—®é—®é¢˜(å…¼å®¹æ¨¡å¼)")
        print("  llmi install <url>  # å®‰è£…æŠ€èƒ½")
        print("  llmi list  # åˆ—å‡ºå·²å®‰è£…çš„æŠ€èƒ½")
        print("  llmi use <tool> [args]  # ä½¿ç”¨å·¥å…·")
        print("  llmi translate <file> [args]  # ç¿»è¯‘æ–‡ä»¶")
        sys.exit(1)
    
    # è·å–æ‰€æœ‰å‚æ•°
    args = sys.argv[1:]
    
    # æ£€æŸ¥ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯å¦æ˜¯'ask'æŒ‡ä»¤
    first_arg = args[0]
    
    if first_arg == 'ask':
        # å…¼å®¹æ¨¡å¼çš„askæŒ‡ä»¤
        if len(args) < 2:
            print("âŒ askæŒ‡ä»¤éœ€è¦æä¾›é—®é¢˜")
            print("Usage: llmi ask \"your question here\" [--file file_path]")
            sys.exit(1)
        
        # å°†å‰©ä½™å‚æ•°åˆå¹¶ä¸ºé—®é¢˜
        user_input = " ".join(args[1:]).strip()
        
        file_path = None
        # æ£€æŸ¥æ˜¯å¦æœ‰--fileå‚æ•°
        if '--file' in args or '-f' in args:
            try:
                file_index = args.index('--file') if '--file' in args else args.index('-f')
                if file_index + 1 < len(args):
                    file_path = args[file_index + 1]
                    # ä»user_inputä¸­ç§»é™¤--fileå’Œfile_path
                    file_part = f"--file {file_path}" if '--file' in args else f"-f {file_path}"
                    user_input = user_input.replace(file_part, "").strip()
            except ValueError:
                pass
    elif first_arg in ['use', 'translate', 'list', 'install']:
        # æŠ€èƒ½ç›¸å…³æŒ‡ä»¤
        if first_arg == 'install':
            # å®‰è£…æŠ€èƒ½
            if len(args) < 2:
                print("âŒ installæŒ‡ä»¤éœ€è¦æä¾›æŠ€èƒ½URL")
                print("Usage: llmi install <skill_url>")
                sys.exit(1)
            
            skill_url = args[1]
            success = install_skill_from_url(skill_url)
            sys.exit(0 if success else 1)
            
        elif first_arg == 'list':
            # åˆ—å‡ºå·²å®‰è£…çš„æŠ€èƒ½
            skills = list_skills()
            if not skills:
                print("ğŸ“‚ æš‚æ— å·²å®‰è£…çš„æŠ€èƒ½")
                print("ä½¿ç”¨ 'llmi install <url>' å®‰è£…æŠ€èƒ½")
            else:
                print("ğŸ“‚ å·²å®‰è£…çš„æŠ€èƒ½:")
                for skill in skills:
                    print(f"  ğŸ“¦ {skill['name']} v{skill['version']}")
                    print(f"     {skill['description']}")
                    if 'author' in skill:
                        print(f"     ä½œè€…: {skill['author']}")
                    print()
            sys.exit(0)
            
        else:
            # æ‰§è¡ŒæŠ€èƒ½
            skill_name = first_arg
            skill_args = args[1:] if len(args) > 1 else []
            
            # æ£€æŸ¥æŠ€èƒ½æ˜¯å¦å­˜åœ¨
            if not load_skill(skill_name):
                print(f"âŒ æŠ€èƒ½ '{skill_name}' ä¸å­˜åœ¨")
                print("ä½¿ç”¨ 'llmi list' æŸ¥çœ‹å·²å®‰è£…çš„æŠ€èƒ½")
                print("ä½¿ç”¨ 'llmi install <url>' å®‰è£…æ–°æŠ€èƒ½")
                sys.exit(1)
            
            # æ‰§è¡ŒæŠ€èƒ½
            success = execute_skill(skill_name, skill_args)
            sys.exit(0 if success else 1)
            
    else:
        # é»˜è®¤è¡Œä¸ºï¼šå°†æ‰€æœ‰å‚æ•°ä½œä¸ºé—®é¢˜å¤„ç†
        user_input = " ".join(args).strip()
        file_path = None
        
        # æ£€æŸ¥æ˜¯å¦æœ‰--fileå‚æ•°
        if '--file' in args or '-f' in args:
            try:
                file_index = args.index('--file') if '--file' in args else args.index('-f')
                if file_index + 1 < len(args):
                    file_path = args[file_index + 1]
                    # ä»user_inputä¸­ç§»é™¤--fileå’Œfile_path
                    file_part = f"--file {file_path}" if '--file' in args else f"-f {file_path}"
                    user_input = user_input.replace(file_part, "").strip()
            except ValueError:
                pass
    
    print(f"ğŸ¤” ç”¨æˆ·æé—®: {user_input}")
    if file_path:
        print(f"ğŸ“ é™„ä»¶æ–‡ä»¶: {file_path}")
    print()

    # è·å–shellä¿¡æ¯
    shell_info = get_shell_info()
    
    # å¤„ç†æ–‡ä»¶é™„ä»¶
    file_info = None
    if file_path:
        print("ğŸ“‚ æ­£åœ¨è¯»å–æ–‡ä»¶...")
        file_info = read_file_content(file_path)
        if file_info.get('error'):
            print(f"âŒ {file_info['error']}")
            sys.exit(1)
        print(f"âœ… æ–‡ä»¶è¯»å–æˆåŠŸ: {file_info['filename']} ({file_info['size']} bytes)")
        print()

    # åˆ›å»ºç»“æ„åŒ–æç¤º
    messages = create_structured_prompt(user_input, shell_info, file_info)

    # ç¡®ä¿ç¯å¢ƒ
    ensure_llm_env()

    # è°ƒç”¨LLM
    print("ğŸ§  æ­£åœ¨æ€è€ƒ...")
    llm_response = call_llm(messages)

    if llm_response.startswith("Error"):
        print(f"{llm_response}")
        sys.exit(1)

    # æå–å‘½ä»¤
    command = extract_command(llm_response)

    print("\nğŸ’¡ LLMå›ç­”:")
    print(llm_response)
    print()

    # å¦‚æœæœ‰å‘½ä»¤ï¼Œæç¤ºç”¨æˆ·å¯ä»¥ä½¿ç”¨
    if command:
        print("=" * 50)
        print("ğŸ“‹ å»ºè®®å‘½ä»¤:")
        print(command)
        print("\nğŸ’¡ æç¤º: æ‚¨å¯ä»¥ä½¿ç”¨Tabé”®å¿«é€Ÿç²˜è´´æ­¤å‘½ä»¤")

        # å°†å‘½ä»¤ç¼“å­˜åˆ°æ–‡ä»¶ï¼Œä¾› shell æŒ‰é”®ç»‘å®šè¯»å–
        try:
            cache_dir = Path(os.path.expanduser("~/.cache/llmi"))
            cache_dir.mkdir(parents=True, exist_ok=True)
            (cache_dir / "last_command").write_text(command + "\n", encoding="utf-8")
        except Exception as _:
            pass

    return command


if __name__ == "__main__":
    main()