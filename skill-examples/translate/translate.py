#!/usr/bin/env python3
"""
ç¿»è¯‘æŠ€èƒ½å¤„ç†è„šæœ¬
ä½¿ç”¨LLMç¿»è¯‘æ–‡ä»¶å†…å®¹
"""

import os
import sys
import json
from pathlib import Path


def main(args):
    """ç¿»è¯‘æŠ€èƒ½çš„ä¸»å‡½æ•°"""
    try:
        from openai import OpenAI
        
        # è§£æå‚æ•°
        if len(args) == 0:
            print("âŒ è¯·æä¾›è¦ç¿»è¯‘çš„æ–‡ä»¶")
            print("Usage: llmi translate <file> [target_lang] [source_lang]")
            return False
        
        file_path = args[0]
        target_lang = args[1] if len(args) > 1 else "en"
        source_lang = args[2] if len(args) > 2 else None
        
        # æ£€æŸ¥æ–‡ä»¶
        abs_path = Path(file_path).expanduser().resolve()
        if not abs_path.exists():
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return False
        
        if not abs_path.is_file():
            print(f"âŒ è·¯å¾„ä¸æ˜¯æ–‡ä»¶: {file_path}")
            return False
        
        # è¯»å–æ–‡ä»¶å†…å®¹
        try:
            with open(abs_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except UnicodeDecodeError:
            print("âŒ ä¸æ”¯æŒç¿»è¯‘äºŒè¿›åˆ¶æ–‡ä»¶")
            return False
        
        if not content.strip():
            print("âš ï¸ æ–‡ä»¶å†…å®¹ä¸ºç©º")
            return True
        
        # æ£€æŸ¥LLMç¯å¢ƒ
        if not os.environ.get('LLM_API_KEY') or not os.environ.get('LLM_BASE_URL'):
            print("âŒ ç¼ºå°‘LLMç¯å¢ƒå˜é‡ï¼Œè¯·å…ˆè¿è¡Œ: source llm-switch")
            return False
        
        print(f"ğŸ” æ­£åœ¨ç¿»è¯‘æ–‡ä»¶: {abs_path.name}")
        print(f"ğŸŒ ç›®æ ‡è¯­è¨€: {target_lang}")
        if source_lang:
            print(f"ğŸŒ æºè¯­è¨€: {source_lang}")
        print()
        
        # æ„å»ºç¿»è¯‘æç¤º
        if source_lang:
            prompt = f"è¯·å°†ä»¥ä¸‹{source_lang}å†…å®¹ç¿»è¯‘æˆ{target_lang}ï¼Œä¿æŒåŸæ–‡æ ¼å¼ï¼š\n\n{content}"
        else:
            prompt = f"è¯·å°†ä»¥ä¸‹å†…å®¹ç¿»è¯‘æˆ{target_lang}ï¼Œä¿æŒåŸæ–‡æ ¼å¼ï¼š\n\n{content}"
        
        # è°ƒç”¨LLM
        client = OpenAI(
            api_key=os.environ.get('LLM_API_KEY'),
            base_url=os.environ.get('LLM_BASE_URL')
        )
        
        response = client.chat.completions.create(
            model=os.environ.get('LLM_MODEL_NAME', 'doubao-seed-1.6-flash'),
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¿»è¯‘åŠ©æ‰‹ï¼Œè¯·å‡†ç¡®ç¿»è¯‘ç”¨æˆ·æä¾›çš„æ–‡æœ¬ï¼Œä¿æŒåŸæœ‰çš„æ ¼å¼å’Œç»“æ„ã€‚"},
                {"role": "user", "content": prompt}
            ],
            max_tokens=4000,
            temperature=0.3
        )
        
        translation = response.choices[0].message.content
        
        print("ğŸ“ ç¿»è¯‘ç»“æœ:")
        print("=" * 50)
        print(translation)
        print("=" * 50)
        
        # ä¿å­˜ç¿»è¯‘ç»“æœ
        output_path = abs_path.parent / f"{abs_path.stem}_{target_lang}{abs_path.suffix}"
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(translation)
        
        print(f"\nâœ… ç¿»è¯‘å®Œæˆï¼Œç»“æœå·²ä¿å­˜åˆ°: {output_path}")
        return True
        
    except Exception as e:
        print(f"âŒ ç¿»è¯‘å¤±è´¥: {e}")
        return False


if __name__ == "__main__":
    main(sys.argv[1:])
